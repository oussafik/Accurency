{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f364f9bf-fa4d-4dfb-a62d-b7fb74ce526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml import PipelineModel\n",
    "from cassandra.cluster import Cluster\n",
    "from pyspark.ml.regression import RandomForestRegressionModel\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a6076d6-c305-4314-bf73-5d377c876081",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Cassandra configuration\n",
    "cassandra_contact_points = ['192.168.1.22']\n",
    "cassandra_keyspace = 'stock_market' \n",
    "cassandra_table = 'coins_prices2'\n",
    "\n",
    "# Connect to the Cassandra cluster\n",
    "cluster = Cluster(cassandra_contact_points)\n",
    "session = cluster.connect()\n",
    "\n",
    "# Switch to the keyspace\n",
    "session.set_keyspace(cassandra_keyspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3453fce8-c2e2-490a-bb46-119d3fa9da4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f681bdb33d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name_pred = \"predprices\"\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name_pred} (\n",
    "        timestamp TIMESTAMP PRIMARY KEY,\n",
    "        symbol TEXT,\n",
    "        prediction TEXT\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6f1f7-de99-4280-890d-cdcb2abae2ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### AAPL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e84e660-859d-4463-8e98-80c16f145e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'AAPL'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "aapl_model = \"/home/jovyan/models/aapl_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(aapl_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbd23b-2c32-4462-9e69-1b9cfbccf7a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### AXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62ad3dea-6407-468a-863b-5dc781a344d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'AXP'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "axpp_model = \"/home/jovyan/models/axpp_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(axpp_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c2d63-ed1f-4ceb-8585-22647c586ac8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96e84d12-c181-435e-afe4-07ec89491c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'AMD'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "amdd_model = \"/home/jovyan/models/amdd_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(amdd_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b943e-cba3-4a9b-b45e-c8bf31c641fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39a9d81b-c63f-4fa3-b479-6cccba891f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'BA'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "baa_model = \"/home/jovyan/models/baa_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(baa_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc05a169-7402-481a-9083-b41b1b11bdd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f41b9ade-a68c-490b-b780-d5ea7a673580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'CAT'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "catt_model = \"/home/jovyan/models/catt_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(catt_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d0a2a-eb3e-4b50-a3de-88216f1d05bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CSCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da591851-f237-4c47-aeb9-81adcd1bca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'CSCO'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "cscoo_model = \"/home/jovyan/models/cscoo_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(cscoo_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b7258-6024-43e0-9898-389575f7d379",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GOOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6a99474-4bef-4b2e-bf16-652a2399c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'GOOG'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "googg_model = \"/home/jovyan/models/googg_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(googg_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed3b82-d8d4-4065-b8be-4c4271f2eac4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GOOGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d17ac5ca-5b3d-424c-86c7-52ebf5204ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'GOOGL'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "googll_model = \"/home/jovyan/models/googll_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(googll_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d890d8e-7c6e-4e0f-830d-575246d1afb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### AMZN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "158faf69-03ab-463a-bce6-49892fc6cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'AMZN'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "amznn_model = \"/home/jovyan/models/amznn_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(amznn_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225760be-8fa0-4a1d-b1d0-82a565c2e2b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CVX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6b9f4bb-5f35-4ed7-8f21-f9cefd8f0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 33706)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Query to retrieve data from the table\n",
    "symbol = 'CVX'\n",
    "query = f\"SELECT id, pc, symbol, t FROM {cassandra_table} WHERE symbol='{symbol}';\"\n",
    "\n",
    "# Execute the query\n",
    "result_set = session.execute(query)\n",
    "\n",
    "cvxx_model = \"/home/jovyan/models/cvxx_model\"\n",
    "t1 = []\n",
    "# Charger le modèle RandomForest à partir du répertoire spécifié\n",
    "rf_model = RandomForestRegressionModel.load(cvxx_model)\n",
    "for row in result_set:\n",
    "    t1.append(row.pc)\n",
    "data = [Row(features=Vectors.dense(t1))]\n",
    "t1_df = spark.createDataFrame(data)\n",
    "\n",
    "# Create a VectorAssembler to assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=['features'], outputCol='features_vector')\n",
    "t1_df = assembler.transform(t1_df)\n",
    "predictions_on_t1 = rf_model.transform(t1_df)\n",
    "# Store the predictions in the Cassandra table\n",
    "for row in predictions_on_t1.collect():\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name_pred} (timestamp, symbol, prediction)\n",
    "        VALUES ('{current_time}', '{symbol}', '{row.prediction}')\n",
    "    \"\"\"\n",
    "    session.execute(insert_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b10eb2-c216-407b-86dc-95cb6336b003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
